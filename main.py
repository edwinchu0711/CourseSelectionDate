import os
import json
import time
import requests
import gc  # å¼•å…¥åƒåœ¾å›æ”¶æ¨¡çµ„
import urllib3
from flask import Flask
import threading
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from datetime import datetime, timedelta, timezone
from google.genai import types
from google import genai

# é—œé–‰ SSL è­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

app = Flask(__name__)

last_scraped_data = None

def get_dynamic_pdf_url():
    chrome_options = Options()
    # åŸºæœ¬ç„¡é ­è¨­å®š
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--ignore-certificate-errors")
    
    # --- è¨˜æ†¶é«”å„ªåŒ–åƒæ•¸ ---
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--disable-extensions")
    chrome_options.add_argument("--disable-dev-tools")
    chrome_options.add_argument("--proxy-server='direct://'")
    chrome_options.add_argument("--proxy-bypass-list=*")
    # ç¦ç”¨åœ–ç‰‡è¼‰å…¥æ˜¯çœè¨˜æ†¶é«”çš„é—œéµ
    chrome_options.add_experimental_option("prefs", {"profile.managed_default_content_settings.images": 2})
    chrome_options.add_argument("--blink-settings=imagesEnabled=false")
    
    try:
        driver = webdriver.Chrome(options=chrome_options)
        base_url = "https://selcrs.nsysu.edu.tw/"
        print(f"æ­£åœ¨è¨ªå•: {base_url}")
        driver.get(base_url)
        
        wait = WebDriverWait(driver, 20)
        # ç­‰å¾…é€£çµå‡ºç¾
        link_element = wait.until(EC.presence_of_element_located((By.PARTIAL_LINK_TEXT, "é¸èª²é ˆçŸ¥")))
        next_url = link_element.get_attribute("href")
        
        print(f"è·³è½‰è‡³: {next_url}")
        driver.get(next_url)
        
        # ç¨å¾®ç­‰å¾…é é¢åŠ è¼‰æ–‡å­—
        time.sleep(3) 
        
        pdf_links = driver.find_elements(By.TAG_NAME, "a")
        for link in pdf_links:
            href = link.get_attribute("href")
            text = link.text
            if href and ".pdf" in href.lower() and "é¸èª²é ˆçŸ¥" in text:
                print(f"âœ… æ‰¾åˆ° PDF: {href}")
                return href
        return None
    except Exception as e:
        print(f"âŒ Selenium éŒ¯èª¤: {e}")
        return None
    finally:
        # ç¢ºä¿ç„¡è«–å¦‚ä½•éƒ½æœƒé—œé–‰ç€è¦½å™¨é‡‹æ”¾è¨˜æ†¶é«”
        if 'driver' in locals():
            driver.quit()

def process_and_save():
    global last_scraped_data
    gc.collect()  # ä¸»å‹•å‘¼å«åƒåœ¾å›æ”¶ï¼Œé‡‹æ”¾è¨˜æ†¶é«”
    print("ğŸš€ é–‹å§‹åŸ·è¡Œè‡ªå‹•åŒ–æµç¨‹...")
    
    # 1. æŠ“å– PDF URL
    pdf_url = get_dynamic_pdf_url()
    if not pdf_url: 
        print("âŒ ç„¡æ³•å–å¾— PDF URL")
        return None
    
    # 2. ä¸‹è¼‰ PDF
    pdf_filename = "/tmp/latest_course_info.pdf"
    try:
        response = requests.get(pdf_url, verify=False, timeout=60)
        with open(pdf_filename, "wb") as f:
            f.write(response.content)
    except Exception as e:
        print(f"âŒ PDF ä¸‹è¼‰å¤±æ•—: {e}")
        return None

    # 3. AI è™•ç† (Gemini)
    try:
        client = genai.Client(api_key=os.environ.get("GEMINI_API_KEY"))
        uploaded_file = client.files.upload(file=pdf_filename)
        
        # ç­‰å¾… AI è™•ç†æ–‡ä»¶
        while uploaded_file.state.name == "PROCESSING":
            time.sleep(3)
            uploaded_file = client.files.get(name=uploaded_file.name)

        prompt = """
        è«‹é–±è®€é€™ä»½é¸èª²é ˆçŸ¥ PDFï¼Œæå–å‡ºä»¥ä¸‹é …ç›®çš„å…·é«”æ™‚é–“ï¼ˆåŒ…å«æ—¥æœŸèˆ‡æ™‚æ®µï¼‰ï¼Œä¸¦åš´æ ¼ä»¥ JSON æ ¼å¼å›å‚³ã€‚
        å¦‚æœæ–‡ä»¶ä¸­æœ‰å¤šå€‹æ™‚æ®µï¼ˆä¾‹å¦‚ä¸åŒå¹´ç´šï¼‰ï¼Œè«‹ä¸€ä½µåˆ—å‡ºã€‚
        
        éœ€æ±‚é …ç›®ï¼š
        1.èª²ç¨‹æŸ¥è©¢
        2.åˆé¸ä¸€
        3.åˆé¸ä¸€å…¬ä½ˆ
        4.åˆé¸äºŒ
        5.åˆé¸äºŒå…¬ä½ˆ
        6.åŠ é€€é¸ä¸€
        7.åŠ é€€é¸ä¸€å…¬ä½ˆ
        8.åŠ é€€é¸äºŒ
        9.åŠ é€€é¸äºŒå…¬ä½ˆ
        10.ç•°å¸¸è™•ç†
        11.é¸èª²ç¢ºèª
        12.æ£„é¸æ™‚é–“  
        13.å¿…ä¿®èª²ç¨‹ç¢ºèª
        14.ç³»æ‰€è¼”å°å­¸ç”Ÿé¸èª²
        15.è¶…ä¿®å­¸åˆ†ç”³è«‹
        (å°±ä»¥ä¸Š15å€‹ï¼Œä¸è¦å…¶ä»–çš„)
        "èª²ç¨‹æŸ¥è©¢"çš„é€™å€‹æ¨™é¡Œå‰é¢å¯ä»¥ä¿ç•™å­¸å¹´åº¦ï¼Œä¾‹å¦‚"110-1 èª²ç¨‹æŸ¥è©¢"
        ç„¶å¾Œæ¯ä¸€é …å°±éƒ½æœ‰é–‹å§‹æ™‚é–“ï¼ŒçµæŸæ™‚é–“ï¼Œè‹¥æ˜¯åªæœ‰å…¶ä¸­ä¸€å€‹é‚£å°±æ˜¯é–‹å§‹æ™‚é–“æœ‰ï¼Œç„¶å¾ŒçµæŸæ™‚é–“å°±ç©ºç™½
        
        ç¯„ä¾‹æ ¼å¼ï¼š
        {
          "114-2 èª²ç¨‹æŸ¥è©¢": { "é–‹å§‹æ™‚é–“": "115å¹´1/6(äºŒ) 13:00", "çµæŸæ™‚é–“": "" },
          "åˆé¸ä¸€": { "é–‹å§‹æ™‚é–“": "1/30(äº”) 09:00", "çµæŸæ™‚é–“": "2/2(ä¸€) 17:00" }
        }(æ—¥æœŸé–“ä¸è¦æœ‰ç©ºç™½ åªæœ‰æ˜ŸæœŸå¾Œå’Œæ™‚é–“å‰å¯ä»¥æœ‰ä¸€å€‹ç©ºç™½)
        æœ€å¾ŒåŠ ä¸Šä¸€å€‹"æ›´æ–°æ™‚é–“"æ¬„ä½ï¼Œå¡«å…¥ç›®å‰çš„æ—¥æœŸæ™‚é–“ã€‚
        """

        response = client.models.generate_content(
            model="gemini-flash-lite-latest", # ä½¿ç”¨æœ€æ–°å¿«é€Ÿæ¨¡å‹
            contents=[
                types.Content(
                    role="user",
                    parts=[
                        types.Part.from_uri(file_uri=uploaded_file.uri, mime_type=uploaded_file.mime_type),
                        types.Part.from_text(text=prompt),
                    ],
                ),
            ],
            config=types.GenerateContentConfig(response_mime_type="application/json")
        )

        data_dict = json.loads(response.text.strip())
        result = {
            "data": data_dict,
            "source_url": pdf_url,
            "update_time": datetime.now(timezone(timedelta(hours=8))).strftime("%Y-%m-%d %H:%M:%S")
        }
        last_scraped_data = result  # å°‡çµæœå­˜å…¥å…¨åŸŸè®Šæ•¸
        gc.collect()
        print("âœ… è³‡æ–™å·²å­˜å…¥æš«å­˜å€")
        return result
    except Exception as e:
        print(f"âŒ AI è™•ç†å¤±æ•—: {e}")
        return None

@app.route('/test')
def index():
    print("å·²å•Ÿå‹•")
    return "Course Scraper is online. Use /run to trigger."

# @app.route('/run')
# def run_scraper():
#     try:
#         data = process_and_save() 
#         if data:
#             return json.dumps(data, ensure_ascii=False), 200, {'Content-Type': 'application/json'}
#         else:
#             return "Failed to extract data", 500
#     except Exception as e:
#         return str(e), 500


@app.route('/run')
def run_scraper():
    # æ”¹å›éåŒæ­¥ï¼šç«‹åˆ»å›å‚³ï¼Œè®“çˆ¬èŸ²åœ¨èƒŒæ™¯è·‘
    threading.Thread(target=process_and_save).start()
    print("é–‹å§‹run")
    return "Task Started", 202
    
@app.route('/get_data')
def get_data():
    print("å·²è¦æ±‚è³‡æ–™")
    global last_scraped_data
    if last_scraped_data:
        print("å·²çµ¦è³‡æ–™")
        return json.dumps(last_scraped_data, ensure_ascii=False), 200, {'Content-Type': 'application/json'}
    print("æœªçµ¦è³‡æ–™")
    return "Data not ready yet", 404

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 10000))
    app.run(host="0.0.0.0", port=port)







